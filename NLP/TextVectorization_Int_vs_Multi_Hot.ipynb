{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgkX8k3H8H9gmVgeY/kz39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santoshrsarangi/tensorflow/blob/main/NLP/TextVectorization_Int_vs_Multi_Hot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4sAlQqjqUsdK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])"
      ],
      "metadata": {
        "id": "uu9xdhb4U1YO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 5000"
      ],
      "metadata": {
        "id": "knmhZQMdVEDN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 4"
      ],
      "metadata": {
        "id": "h_9uSC6QVHZ_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#comment this section if you are trying the \"multi_hot\" mode. Notice the differenc when you call the model.predict or the layer directly on the data\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_len\n",
        ")"
      ],
      "metadata": {
        "id": "1TIJj2-rVL56"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comment this section if you are trying out the \"int\" mode. Notice the differenc when you call the model.predict or the layer directly on the data\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"multi_hot\"\n",
        ")"
      ],
      "metadata": {
        "id": "N4tQUo0kdJBT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(text_dataset.batch(64))"
      ],
      "metadata": {
        "id": "KGzsCv7XVchC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "Qh0LH47-VjvB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))"
      ],
      "metadata": {
        "id": "PGwVGCC_Vs16"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(vectorize_layer)"
      ],
      "metadata": {
        "id": "m4GxdLMUV1EL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = [[\"foo qux bar\"], [\"qux baz\"], [\"foo bar baz\"], [\"qux qwe baz\"], [\"hello\"]]"
      ],
      "metadata": {
        "id": "PbhgkPYHV9Rv"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vectorize_layer(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99WwwPEdsMOp",
        "outputId": "010fe63f-6e41-4615-a803-4182d2ea4b96"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=int64, numpy=\n",
              "array([[1, 1, 1, 0],\n",
              "       [1, 1, 0, 0],\n",
              "       [1, 1, 1, 0],\n",
              "       [1, 1, 1, 0],\n",
              "       [1, 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfYNDoHWG39",
        "outputId": "a567f72b-fa81-4e0f-8922-cf5d7d169938"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 0., 1.],\n",
              "       [1., 0., 1., 0.],\n",
              "       [0., 1., 1., 1.],\n",
              "       [1., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [\"earth\", \"wind\", \"and\", \"fire\"]"
      ],
      "metadata": {
        "id": "4FVppmi3WK1D"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode= \"int\",\n",
        "    output_sequence_length=max_len,\n",
        "    vocabulary=vocab\n",
        ")"
      ],
      "metadata": {
        "id": "w3pcJe1bWu1m"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V2ZJLgoXBoz",
        "outputId": "35d4ee34-08cc-4203-b382-389d62c07edc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'earth', 'wind', 'and', 'fire']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN4-m36YXKH9",
        "outputId": "a167e3d9-2387-4df8-f635-365aabb1de85"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'earth', 'wind', 'and', 'fire']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}